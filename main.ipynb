{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.utils_ import log_string, plot_train_val_loss\n",
    "from utils.utils_ import count_parameters, load_data\n",
    "\n",
    "from model.model_ import GMAN\n",
    "from model.train import train\n",
    "from model.test import test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_slot=5, num_his=12, num_pred=12, L=1, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=32, max_epoch=1, patience=10, learning_rate=0.001, decay_epoch=10, traffic_file='./data/pems-bay.h5', SE_file='./data/SE(PeMS).txt', model_file='./data/GMAN.pkl', log_file='./data/log'\n",
      "loading data...\n",
      "trainX: torch.Size([36458, 12, 325])\t\t trainY: torch.Size([36458, 12, 325])\n",
      "valX:   torch.Size([5189, 12, 325])\t\tvalY:   torch.Size([5189, 12, 325])\n",
      "testX:   torch.Size([10400, 12, 325])\t\ttestY:   torch.Size([10400, 12, 325])\n",
      "mean:   62.7354\t\tstd:   9.4388\n",
      "data loaded!\n",
      "compiling model...\n",
      "trainable parameters: 209,923\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--time_slot', type=int, default=5,\n",
    "                    help='a time step is 5 mins')\n",
    "parser.add_argument('--num_his', type=int, default=12,\n",
    "                    help='history steps')\n",
    "parser.add_argument('--num_pred', type=int, default=12,\n",
    "                    help='prediction steps')\n",
    "parser.add_argument('--L', type=int, default=1,\n",
    "                    help='number of STAtt Blocks')\n",
    "parser.add_argument('--K', type=int, default=8,\n",
    "                    help='number of attention heads')\n",
    "parser.add_argument('--d', type=int, default=8,\n",
    "                    help='dims of each head attention outputs')\n",
    "parser.add_argument('--train_ratio', type=float, default=0.7,\n",
    "                    help='training set [default : 0.7]')\n",
    "parser.add_argument('--val_ratio', type=float, default=0.1,\n",
    "                    help='validation set [default : 0.1]')\n",
    "parser.add_argument('--test_ratio', type=float, default=0.2,\n",
    "                    help='testing set [default : 0.2]')\n",
    "parser.add_argument('--batch_size', type=int, default=32,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--max_epoch', type=int, default=1,\n",
    "                    help='epoch to run')\n",
    "parser.add_argument('--patience', type=int, default=10,\n",
    "                    help='patience for early stop')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--decay_epoch', type=int, default=10,\n",
    "                    help='decay epoch')\n",
    "parser.add_argument('--traffic_file', default='./data/pems-bay.h5',\n",
    "                    help='traffic file')\n",
    "parser.add_argument('--SE_file', default='./data/SE(PeMS).txt',\n",
    "                    help='spatial embedding file')\n",
    "parser.add_argument('--model_file', default='./data/GMAN.pkl',\n",
    "                    help='save the model to disk')\n",
    "parser.add_argument('--log_file', default='./data/log',\n",
    "                    help='log file')\n",
    "args, unknown = parser.parse_known_args()\n",
    "log = open(args.log_file, 'w')\n",
    "log_string(log, str(args)[10: -1])\n",
    "T = 24 * 60 // args.time_slot  # Number of time steps in one day\n",
    "# load data\n",
    "log_string(log, 'loading data...')\n",
    "(trainX, trainTE, trainY, valX, valTE, valY, testX, testTE,\n",
    "testY, SE, mean, std) = load_data(args)\n",
    "log_string(log, f'trainX: {trainX.shape}\\t\\t trainY: {trainY.shape}')\n",
    "log_string(log, f'valX:   {valX.shape}\\t\\tvalY:   {valY.shape}')\n",
    "log_string(log, f'testX:   {testX.shape}\\t\\ttestY:   {testY.shape}')\n",
    "log_string(log, f'mean:   {mean:.4f}\\t\\tstd:   {std:.4f}')\n",
    "log_string(log, 'data loaded!')\n",
    "del trainX, trainTE, valX, valTE, testX, testTE, mean, std\n",
    "# build model\n",
    "log_string(log, 'compiling model...')\n",
    "\n",
    "model = GMAN(SE, args, bn_decay=0.1)\n",
    "loss_criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                      step_size=args.decay_epoch,\n",
    "                                      gamma=0.9)\n",
    "parameters = count_parameters(model)\n",
    "log_string(log, 'trainable parameters: {:,}'.format(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "A load persistent id instruction was encountered,\nbut no persistent_load function was specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/GMAN.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: A load persistent id instruction was encountered,\nbut no persistent_load function was specified."
     ]
    }
   ],
   "source": [
    "with open('data/GMAN.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
